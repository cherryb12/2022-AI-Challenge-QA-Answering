
# Question Answering Model

[2022ë…„ ì¸ê³µì§€ëŠ¥ ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ](https://aichallenge.or.kr/competition/detail/1)ì—ì„œ ìì—°ì–´ ì˜ì—­ì˜ ë¬¸ì„œ ê²€ìƒ‰ íš¨ìœ¨í™”ë¥¼ ìœ„í•œ ê¸°ê³„ë…í•´ ê³¼ì œì— ì°¸ì—¬í–ˆìœ¼ë©°, ì´ëŠ”
í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë³¸ë¬¸ì—ì„œ ì§ˆë¬¸ì˜ ë‹µì„ ì°¾ëŠ” ë¬¸ì œì´ë‹¤. PLM(Pretrained Language Model)ì„ í™œìš©í•´ ë³¸ë¬¸ê³¼ ì§ˆë¬¸, ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µì„ í•™ìŠµì‹œí‚¤ ë”¥ëŸ¬ë‹ìœ¼ë¡œ í•˜ì—¬ê¸ˆ ë¬¸ë§¥ê³¼ íŒ¨í„´ ë“±ì„ í•™ìŠµì‹œí‚¤ê³  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì •ë‹µì„ ì˜ˆì¸¡í•˜ë„ë¡ í•œë‹¤. ì •í™•íˆëŠ” ë³¸ë¬¸ì—ì„œ ì •ë‹µì´ ë˜ëŠ” í…ìŠ¤íŠ¸ì˜ ì‹œì‘ ì¸ë±ìŠ¤ì™€ ì¢…ë£Œ ì¸ë±ìŠ¤ë¥¼ ì˜ˆì¸¡í•œë‹¤.

HuggingFaceğŸ¤—ì˜ [Question Answering Tutorial](https://huggingface.co/docs/transformers/tasks/question_answering)ì„ ì°¸ê³ í•´ ë² ì´ìŠ¤ë¼ì¸ì„ ì‘ì„±í–ˆìœ¼ë©°, ì •ë‹µì´ ì—†ëŠ” ê²½ìš°ë¥¼ í•™ìŠµì‹œì¼œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²°ê³¼ë¥¼ ì œì¶œí•œ ê²°ê³¼ exact match ì ìˆ˜ëŠ” 0.8 ì´ìƒì„ ì•ˆì •ì ìœ¼ë¡œ ê¸°ë¡í–ˆë‹¤. ì—¬ê¸°ì— ì—¬ëŸ¬ê°€ì§€ í•œêµ­ì–´ PLMì„ í…ŒìŠ¤íŒ…í•˜ê³  ìµœì¢… ì •ë‹µì„ ì¶”ì¶œí•˜ëŠ” ìƒ˜í”Œë§ ë°©ë²•, í•˜ì´í¼ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŒ…ì„ ì§„í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í–ˆë‹¤. 

ê¸°ê³„ë…í•´ ë¬¸ì œì˜ ì–´ë ¤ìš´ ì :
1. ì£¼ì–´ì§„ ë³¸ë¬¸ì—ì„œ ë‹µì„ ì°¾ì•„ì•¼ í•˜ëŠ” ë¬¸ì œë¡œ ì§ˆë¬¸ì´ ì• ë§¤í•˜ë©´ ë‹µì„ ì˜ ì¶”ë¡ í•˜ì§€ ëª»í•œë‹¤. 
2. ë¶€ë¶„ì ìœ¼ë¡œ ë‹µì´ ë§ë”ë¼ê³  í•˜ë”ë¼ê³  ì •í™•í•˜ê²Œ ë‹µì˜ ì²˜ìŒê³¼ ëì´ ë§ì§€ ì•Šìœ¼ë©´ í‹€ë¦°ë‹¤. (ìƒ˜í”Œë§ ë°©ë²• ì¤‘ìš”)
3. ë³¸ë¬¸ê³¼ ìœ ì‚¬í•œ í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ê±°ë‚˜ ìš°íšŒì ìœ¼ë¡œ ì§ˆë¬¸í•˜ë©´ ë‹µì„ ì˜ ì¶”ë¡ í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤.

---

## How to Use

### Install python libraries

```bash
pip install numpy==1.20.1
pip install transformers
pip install datasets
```

### Hyperparameter testing

This is a template repository for Text Classification using Optimum and onnxruntime to support generic inference with Hugging Face Hub generic Inference API. There are two required steps:

1. Specify the requirements by defining a `requirements.txt` file.
2. Implement the `pipeline.py` `__init__` and `__call__` methods. These methods are called by the Inference API. The `__init__` method should load the model and preload the optimum model and tokenizers as well as the `text-classification` pipeline needed for inference. This is only called once. The `__call__` method performs the actual inference. Make sure to follow the same input/output specifications defined in the template for the pipeline to work.

add 
```
library_name: generic
```
to the readme.

ë¨¸ë¨¸ë¨¸ í•´ì„œ ê²°ê³¼ ì œì¶œ í–ˆì„ ë•Œ 08.-0.87 ìµœì¢… 6ìœ„ë¡œ ëë‚¨
